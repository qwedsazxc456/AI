{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9370fe6-8a98-4d29-be85-30790921a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms , models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67821c10-de1b-49fd-af4f-1b16fab4fe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/data/train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c082c7-4e02-43fa-83c3-80afea8fcdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydataset():\n",
    "    def __init__(self):\n",
    "        path=os.path.join(os.getcwd(),'input/data/train/images')\n",
    "        imagelist=[]\n",
    "        labellist=[]\n",
    "        for folder in os.listdir(path):\n",
    "            if folder.startswith('.'):\n",
    "                continue\n",
    "            id,gender,race,age = folder.split('_')\n",
    "            age = int(age) - 18\n",
    "            # 자료가 18세부터 60세까지의 자료만 있음 \n",
    "            # 시작이 0부터 시작해서 똑같이 끝나지 않으면 오류생김\n",
    "            for image in os.listdir(os.path.join(path, folder)):\n",
    "                if image.startswith('.'):\n",
    "                    continue\n",
    "                mask,ext=image.split('.')\n",
    "                imagelist.append(os.path.join(path,folder,image))\n",
    "                labellist.append(age)\n",
    "        self.imagelist=imagelist\n",
    "        self.labellist=labellist\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagelist)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        image_path = self.imagelist[idx]\n",
    "        image = Image.open(image_path)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()            \n",
    "        ])\n",
    "        image = transform(image)\n",
    "        label = self.labellist[idx]\n",
    "        return image,label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f359964a-e826-4aca-b34c-1152a48e1ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=mydataset()\n",
    "dataset[0][0].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa4a65d-0e8f-4040-b0b9-57f58f87ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=mydataset()\n",
    "split=torch.utils.data.random_split(dataset, [int(18900*0.8), int(18900*0.2)])\n",
    "trainset,valset = split[0],split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0276273b-3537-40f8-b098-ff52f77f56b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    valset,\n",
    "    batch_size=256,\n",
    "    num_workers=0,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "453b5845-00cd-48cd-97b2-94fec2114c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mymodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        self.model.fc=nn.Linear(512,43)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.x=self.model(self.x)\n",
    "        return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccbaeda2-52ac-4e96-a61c-c1a1bdfdbc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model=mymodel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "715aad11-80ae-4d3c-8bfe-3ad70b7d0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04aa5fb-6045-44d0-b2d0-b05bead3c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:31,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 0.013\n",
      "21.607142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 60] loss: 0.009\n",
      "31.931216931216934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:31,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 60] loss: 0.008\n",
      "36.11111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 60] loss: 0.008\n",
      "39.82804232804233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 60] loss: 0.007\n",
      "40.925925925925924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 60] loss: 0.007\n",
      "43.379629629629626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 60] loss: 0.007\n",
      "46.13095238095239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.007\n",
      "45.535714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 60] loss: 0.006\n",
      "49.107142857142854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 60] loss: 0.006\n",
      "49.404761904761905\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "batch_size=256\n",
    "acc = 0\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, data in tqdm(enumerate(train_loader)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda() , labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        correct += (preds==labels).sum().item()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.data\n",
    "    print('[%d, %d] loss: %.3f' %\n",
    "      (epoch + 1, i + 1, running_loss / len(trainset)))\n",
    "    running_loss = 0.0\n",
    "    print(correct / len(trainset)*100)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87d43365-5ca8-4b75-8232-75249b5b7b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:01<00:22,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:03<00:20,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:04<00:18,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 4/15 [00:06<00:17,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:07<00:15,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:09<00:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:10<00:12,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 8/15 [00:12<00:10,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9/15 [00:14<00:09,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:15<00:07,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:17<00:06,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:18<00:04,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 13/15 [00:20<00:03,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 14/15 [00:21<00:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([196, 3, 512, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:23<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.17460317460317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct=0\n",
    "    model.eval()\n",
    "    for val_batch in tqdm(val_loader):\n",
    "        inputs, labels = val_batch\n",
    "        print(inputs.size())\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, dim=-1)\n",
    "        correct += (preds==labels).sum().item()\n",
    "    print(correct / len(valset)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf5e6cb-bafd-4e6b-958c-0d4eae15ca70",
   "metadata": {},
   "source": [
    "#### 실제 사진으로 한장씩 확인해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4a9d0ea-b7c3-4e48-b5dd-89551390660e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.6623, 10.5897, 10.3963,  2.8233,  1.9469,  9.0538,  5.4880,  5.5218,\n",
      "          0.6536, -1.0104,  4.7255, -0.8707,  1.5600, -4.9228, -4.1081, -5.4867,\n",
      "         -3.4603, -2.7632, -2.4701, -1.4610,  1.8224, -6.0496,  3.3955, -3.1493,\n",
      "          1.5989,  2.8660,  0.3367, -0.9978, -7.3849,  2.3463,  0.1550, -1.2434,\n",
      "          5.4339,  3.2828,  3.4053,  4.8501,  1.3520,  6.8891,  6.7978,  6.3045,\n",
      "          5.7287,  8.8247,  6.8066]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(os.path.join(os.getcwd()+'/20220306_085949.jpg'))\n",
    "trans = transforms.Compose([\n",
    "transforms.Resize((512,384)), # 학습에 사용한 사진의 사이즈로 바꾸기\n",
    "transforms.ToTensor()])\n",
    "image = trans(image)\n",
    "image = image.unsqueeze(0) # 모양이 달라서 안돌아가기 때문에 3-dim에서 4-dim으로 바꾸기\n",
    "image = image.to(device) # model이 cuda에 있기 때문에 image를 cuda로 보내야한다\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    out = model(image)\n",
    "\n",
    "\n",
    "# print(torch.argmax(out,1)+18) # 숫자를 맞추기 위해 18을 뺏기 때문에 다시 더해준다\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa57f36-99f9-4070-a07a-4602820590c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
